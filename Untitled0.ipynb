{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGjQnLSAm8h6",
        "outputId": "666e9f47-20a9-4de7-d8be-1112d2f8e2c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instala las dependencias de PyG (¡El paso que siempre funciona en Colab!)\n",
        "!pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-$(python -c 'import torch; print(torch.__version__)').html\n",
        "\n",
        "# Instalamos el resto de nuestras herramientas\n",
        "!pip install pandas scikit-learn matplotlib seaborn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkotXHprnUn4",
        "outputId": "eb6250b8-5ddf-4efd-a2a5-b7478d097aab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcu126/torch_scatter-2.1.2%2Bpt28cu126-cp312-cp312-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcu126/torch_sparse-0.6.18%2Bpt28cu126-cp312-cp312-linux_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter, torch-sparse, torch-geometric\n",
            "Successfully installed torch-geometric-2.7.0 torch-scatter-2.1.2+pt28cu126 torch-sparse-0.6.18+pt28cu126\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Asegúrate que la ruta sea correcta. 'My Drive' es como Google Drive llama a tu unidad principal\n",
        "zip_path = \"/content/drive/My Drive/Colab Notebooks/Proyecto_GNN_Fraude/archive (2).zip\"\n",
        "\n",
        "# El -o es para que \"sobrescriba\" sin preguntar\n",
        "# El -q es para que lo haga \"en silencio\"\n",
        "!unzip -oq \"{zip_path}\"\n",
        "\n",
        "print(\"¡Archivos descomprimidos con éxito!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjq61IXXn9yH",
        "outputId": "a667ad88-5229-4c3f-efb1-c14af9d05607"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡Archivos descomprimidos con éxito!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ¡Recordemos la lección! Los nombres de archivo con mayúsculas y espacios\n",
        "path_transacciones = 'Data/Transaction Data/transaction_records.csv'\n",
        "path_clientes = 'Data/Customer Profiles/Customer Profiles.csv'\n",
        "path_comercios = 'Data/Merchant Information/merchant_data.csv'\n",
        "\n",
        "print(f\"Cargando transacciones desde: {path_transacciones}\")\n",
        "df_transactions = pd.read_csv(path_transacciones)\n",
        "\n",
        "print(f\"Cargando clientes desde: {path_clientes}\")\n",
        "df_customers = pd.read_csv(path_clientes)\n",
        "\n",
        "print(f\"Cargando comercios desde: {path_comercios}\")\n",
        "df_merchants = pd.read_csv(path_comercios)\n",
        "\n",
        "print(\"\\n--- ¡ÉXITO! Datos de Transacciones: ---\")\n",
        "print(df_transactions.head())\n",
        "\n",
        "print(\"\\n--- ¡ÉXITO! Datos de Clientes: ---\")\n",
        "print(df_customers.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "-usoXbpkoCn4",
        "outputId": "a359dc78-df69-434a-b0cb-11e0152897f4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando transacciones desde: Data/Transaction Data/transaction_records.csv\n",
            "Cargando clientes desde: Data/Customer Profiles/Customer Profiles.csv\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Data/Customer Profiles/Customer Profiles.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1441504123.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Cargando clientes desde: {path_clientes}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdf_customers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_clientes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Cargando comercios desde: {path_comercios}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/Customer Profiles/Customer Profiles.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ¡VUELVE A EJECUTAR ESTA CELDA!\n",
        "zip_path = \"/content/drive/My Drive/Colab Notebooks/Proyecto_GNN_Fraude/archive (2).zip\"\n",
        "!unzip -oq \"{zip_path}\"\n",
        "print(\"¡Archivos descomprimidos con éxito!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPyR7xFkoXMi",
        "outputId": "b82efd41-474b-43c6-8b0a-638bbb4355a3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡Archivos descomprimidos con éxito!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ¡Recordemos la lección! Los nombres de archivo con mayúsculas y espacios\n",
        "path_transacciones = 'Data/Transaction Data/transaction_records.csv'\n",
        "path_clientes = 'Data/Customer Profiles/Customer Profiles.csv'\n",
        "path_comercios = 'Data/Merchant Information/merchant_data.csv'\n",
        "\n",
        "print(f\"Cargando transacciones desde: {path_transacciones}\")\n",
        "df_transactions = pd.read_csv(path_transacciones)\n",
        "\n",
        "print(f\"Cargando clientes desde: {path_clientes}\")\n",
        "df_customers = pd.read_csv(path_clientes)\n",
        "\n",
        "print(f\"Cargando comercios desde: {path_comercios}\")\n",
        "df_merchants = pd.read_csv(path_comercios)\n",
        "\n",
        "print(\"\\n--- ¡ÉXITO! Datos de Transacciones: ---\")\n",
        "print(df_transactions.head())\n",
        "\n",
        "print(\"\\n--- ¡ÉXITO! Datos de Clientes: ---\")\n",
        "print(df_customers.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "KF313knOolKN",
        "outputId": "199ab8a6-361e-44e1-fd36-fcf00552801a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando transacciones desde: Data/Transaction Data/transaction_records.csv\n",
            "Cargando clientes desde: Data/Customer Profiles/Customer Profiles.csv\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Data/Customer Profiles/Customer Profiles.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3125302268.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Cargando clientes desde: {path_clientes}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdf_customers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_clientes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Cargando comercios desde: {path_comercios}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/Customer Profiles/Customer Profiles.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Esta ruta parece estar bien\n",
        "path_transacciones = 'Data/Transaction Data/transaction_records.csv'\n",
        "\n",
        "# ¡¡AQUÍ ESTÁ EL ARREGLO!! El archivo se llama 'customer_data.csv'\n",
        "path_clientes = 'Data/Customer Profiles/customer_data.csv'\n",
        "\n",
        "# Esta ruta probablemente también está bien\n",
        "path_comercios = 'Data/Merchant Information/merchant_data.csv'\n",
        "\n",
        "# --- ¡AHORA EJECUTA ESTA CELDA! ---\n",
        "\n",
        "print(f\"Cargando transacciones desde: {path_transacciones}\")\n",
        "df_transactions = pd.read_csv(path_transacciones)\n",
        "\n",
        "print(f\"Cargando clientes desde: {path_clientes}\")\n",
        "df_customers = pd.read_csv(path_clientes) # ¡Esta es la línea que fallaba!\n",
        "\n",
        "print(f\"Cargando comercios desde: {path_comercios}\")\n",
        "df_merchants = pd.read_csv(path_comercios)\n",
        "\n",
        "print(\"\\n--- ¡ÉXITO! Datos de Transacciones: ---\")\n",
        "print(df_transactions.head())\n",
        "\n",
        "print(\"\\n--- ¡ÉXITO! Datos de Clientes: ---\")\n",
        "print(df_customers.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUvHEbHdtHnV",
        "outputId": "6e1e9358-7125-46f4-b1d4-9100a46251ce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando transacciones desde: Data/Transaction Data/transaction_records.csv\n",
            "Cargando clientes desde: Data/Customer Profiles/customer_data.csv\n",
            "Cargando comercios desde: Data/Merchant Information/merchant_data.csv\n",
            "\n",
            "--- ¡ÉXITO! Datos de Transacciones: ---\n",
            "   TransactionID     Amount  CustomerID\n",
            "0              1  55.530334        1952\n",
            "1              2  12.881180        1027\n",
            "2              3  50.176322        1955\n",
            "3              4  41.634001        1796\n",
            "4              5  78.122853        1946\n",
            "\n",
            "--- ¡ÉXITO! Datos de Clientes: ---\n",
            "   CustomerID           Name  Age       Address\n",
            "0        1001  Customer 1001   54  Address 1001\n",
            "1        1002  Customer 1002   35  Address 1002\n",
            "2        1003  Customer 1003   40  Address 1003\n",
            "3        1004  Customer 1004   30  Address 1004\n",
            "4        1005  Customer 1005   46  Address 1005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ¡Cargar el \"Crimen\" (La etiqueta de fraude) ---\n",
        "# (Asumo que el archivo se llama 'fraud_indicators.csv' dentro de la carpeta)\n",
        "path_fraude = 'Data/Fraudulent Patterns/fraud_indicators.csv'\n",
        "\n",
        "print(f\"Cargando indicadores de fraude desde: {path_fraude}\")\n",
        "df_fraud = pd.read_csv(path_fraude)\n",
        "\n",
        "print(\"\\n--- ¡ÉXITO! Datos de Fraude: ---\")\n",
        "print(df_fraud.head())\n",
        "print(df_fraud.info())\n",
        "\n",
        "\n",
        "# --- ¡Cargar las \"Conexiones\" (Los links del grafo) ---\n",
        "path_metadata = 'Data/Transaction Data/transaction_metadata.csv'\n",
        "\n",
        "print(f\"\\nCargando 'metadata' de transacciones desde: {path_metadata}\")\n",
        "df_metadata = pd.read_csv(path_metadata)\n",
        "\n",
        "print(\"\\n--- ¡ÉXITO! Datos de Metadata: ---\")\n",
        "print(df_metadata.head())\n",
        "print(df_metadata.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSYP3wautzIi",
        "outputId": "45580293-ce58-4f1c-a7a9-aedee5833fef"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando indicadores de fraude desde: Data/Fraudulent Patterns/fraud_indicators.csv\n",
            "\n",
            "--- ¡ÉXITO! Datos de Fraude: ---\n",
            "   TransactionID  FraudIndicator\n",
            "0              1               0\n",
            "1              2               0\n",
            "2              3               0\n",
            "3              4               0\n",
            "4              5               0\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 2 columns):\n",
            " #   Column          Non-Null Count  Dtype\n",
            "---  ------          --------------  -----\n",
            " 0   TransactionID   1000 non-null   int64\n",
            " 1   FraudIndicator  1000 non-null   int64\n",
            "dtypes: int64(2)\n",
            "memory usage: 15.8 KB\n",
            "None\n",
            "\n",
            "Cargando 'metadata' de transacciones desde: Data/Transaction Data/transaction_metadata.csv\n",
            "\n",
            "--- ¡ÉXITO! Datos de Metadata: ---\n",
            "   TransactionID            Timestamp  MerchantID\n",
            "0              1  2022-01-01 00:00:00        2701\n",
            "1              2  2022-01-01 01:00:00        2070\n",
            "2              3  2022-01-01 02:00:00        2238\n",
            "3              4  2022-01-01 03:00:00        2879\n",
            "4              5  2022-01-01 04:00:00        2966\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 3 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   TransactionID  1000 non-null   int64 \n",
            " 1   Timestamp      1000 non-null   object\n",
            " 2   MerchantID     1000 non-null   int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 23.6+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 1: Unimos las transacciones con su metadata\n",
        "# Usamos 'TransactionID' como la llave (on=) para unirlas\n",
        "df_master = pd.merge(df_transactions,\n",
        "                     df_metadata,\n",
        "                     on='TransactionID',\n",
        "                     how='inner')\n",
        "\n",
        "# Paso 2: Unimos esa tabla nueva con los indicadores de fraude\n",
        "# De nuevo, usamos 'TransactionID' como la llave\n",
        "df_master = pd.merge(df_master,\n",
        "                     df_fraud,\n",
        "                     on='TransactionID',\n",
        "                     how='inner')\n",
        "\n",
        "# --- ¡Veamos nuestro Súper-DataFrame! ---\n",
        "print(\"¡Tabla Maestra creada con éxito!\")\n",
        "print(f\"Total de transacciones: {len(df_master)}\")\n",
        "\n",
        "print(\"\\n--- Vistazo a la Tabla Maestra ---\")\n",
        "print(df_master.head())\n",
        "\n",
        "print(\"\\n--- Columnas de nuestra Tabla Maestra (¡Lo tenemos todo!) ---\")\n",
        "df_master.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJRhUTAvu2NN",
        "outputId": "5921dfe0-3ab0-4509-901f-d7a6612a4fc8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡Tabla Maestra creada con éxito!\n",
            "Total de transacciones: 1000\n",
            "\n",
            "--- Vistazo a la Tabla Maestra ---\n",
            "   TransactionID     Amount  CustomerID            Timestamp  MerchantID  \\\n",
            "0              1  55.530334        1952  2022-01-01 00:00:00        2701   \n",
            "1              2  12.881180        1027  2022-01-01 01:00:00        2070   \n",
            "2              3  50.176322        1955  2022-01-01 02:00:00        2238   \n",
            "3              4  41.634001        1796  2022-01-01 03:00:00        2879   \n",
            "4              5  78.122853        1946  2022-01-01 04:00:00        2966   \n",
            "\n",
            "   FraudIndicator  \n",
            "0               0  \n",
            "1               0  \n",
            "2               0  \n",
            "3               0  \n",
            "4               0  \n",
            "\n",
            "--- Columnas de nuestra Tabla Maestra (¡Lo tenemos todo!) ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 6 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   TransactionID   1000 non-null   int64  \n",
            " 1   Amount          1000 non-null   float64\n",
            " 2   CustomerID      1000 non-null   int64  \n",
            " 3   Timestamp       1000 non-null   object \n",
            " 4   MerchantID      1000 non-null   int64  \n",
            " 5   FraudIndicator  1000 non-null   int64  \n",
            "dtypes: float64(1), int64(4), object(1)\n",
            "memory usage: 47.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import HeteroData\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# --- 1. Importar la librería de Grafo ---\n",
        "# HeteroData es el \"contenedor\" especial para grafos con\n",
        "# diferentes tipos de nodos y relaciones.\n",
        "data = HeteroData()\n",
        "\n",
        "# --- 2. Crear los Mapeos de Índices ---\n",
        "# Usamos un \"codificador\" para convertir los IDs originales (ej: 1001)\n",
        "# en índices que empiecen en 0 (ej: 0)\n",
        "customer_encoder = LabelEncoder()\n",
        "merchant_encoder = LabelEncoder()\n",
        "\n",
        "# Creamos las nuevas columnas con los índices correctos\n",
        "df_master['customer_idx'] = customer_encoder.fit_transform(df_master['CustomerID'])\n",
        "df_master['merchant_idx'] = merchant_encoder.fit_transform(df_master['MerchantID'])\n",
        "\n",
        "# --- 3. Cargar los NODOS en el Grafo ---\n",
        "# Por ahora, solo le decimos a PyG CUÁNTOS nodos hay de cada tipo.\n",
        "data['cliente'].num_nodes = len(df_master['customer_idx'].unique())\n",
        "data['comercio'].num_nodes = len(df_master['merchant_idx'].unique())\n",
        "\n",
        "# --- 4. Cargar las CONEXIONES (Edges) en el Grafo ---\n",
        "# Esta es la parte más importante.\n",
        "# Creamos la lista de \"quién\" (source) se conecta con \"quién\" (destination)\n",
        "source = torch.tensor(df_master['customer_idx'].values, dtype=torch.long)\n",
        "destination = torch.tensor(df_master['merchant_idx'].values, dtype=torch.long)\n",
        "\n",
        "# Le decimos a PyG: \"Hay una conexión del tipo 'cliente' al 'comercio'\n",
        "# llamada 'hizo_compra_en', y estas son sus conexiones.\"\n",
        "edge_index = torch.stack([source, destination])\n",
        "data['cliente', 'hizo_compra_en', 'comercio'].edge_index = edge_index\n",
        "\n",
        "# --- 5. Cargar las CARACTERÍSTICAS (Features) de las Conexiones ---\n",
        "# ¿Qué describe a esta conexión? ¡El monto (Amount)!\n",
        "# Lo convertimos a un tensor de tipo float\n",
        "edge_features = torch.tensor(df_master['Amount'].values, dtype=torch.float)\n",
        "data['cliente', 'hizo_compra_en', 'comercio'].edge_attr = edge_features.view(-1, 1) # Lo ponemos en formato [N_edges, 1]\n",
        "\n",
        "# --- 6. Cargar las ETIQUETAS (Labels) que queremos predecir ---\n",
        "# ¿Qué queremos predecir? ¡El 'FraudIndicator'!\n",
        "# Lo convertimos a un tensor de tipo long (para clasificación)\n",
        "labels = torch.tensor(df_master['FraudIndicator'].values, dtype=torch.long)\n",
        "data['cliente', 'hizo_compra_en', 'comercio'].y = labels\n",
        "\n",
        "# --- ¡LISTO! ¡Veamos nuestro Grafo! ---\n",
        "print(\"¡Grafo Heterogéneo creado con éxito!\")\n",
        "print(\"=======================================\")\n",
        "print(data)\n",
        "\n",
        "print(\"\\n¿Hay algún problema en el grafo?\")\n",
        "print(data.validate())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnq54sKPvdNt",
        "outputId": "ff184622-6d9c-41b2-94d8-2682685700c2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡Grafo Heterogéneo creado con éxito!\n",
            "=======================================\n",
            "HeteroData(\n",
            "  cliente={ num_nodes=636 },\n",
            "  comercio={ num_nodes=651 },\n",
            "  (cliente, hizo_compra_en, comercio)={\n",
            "    edge_index=[2, 1000],\n",
            "    edge_attr=[1000, 1],\n",
            "    y=[1000],\n",
            "  }\n",
            ")\n",
            "\n",
            "¿Hay algún problema en el grafo?\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Tenemos 1000 conexiones (edges)\n",
        "num_edges = data['cliente', 'hizo_compra_en', 'comercio'].num_edges\n",
        "\n",
        "# Creamos un array de índices, de 0 a 999\n",
        "edge_indices = torch.arange(num_edges)\n",
        "\n",
        "# ¡Usamos sklearn para dividir los ÍNDICES!\n",
        "# Dividimos 80% para entrenar, 20% para probar\n",
        "# random_state=42 es para que la división sea siempre la misma y podamos repetir el experimento\n",
        "train_indices, test_indices = train_test_split(\n",
        "    edge_indices,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# --- Ahora creamos \"Máscaras\" (Masks) ---\n",
        "# PyG ama las máscaras. Son un array de True/False del tamaño de los edges\n",
        "train_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
        "test_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
        "\n",
        "# Ponemos 'True' en las posiciones que pertenecen al set de entrenamiento\n",
        "train_mask[train_indices] = True\n",
        "# Ponemos 'True' en las posiciones que pertenecen al set de prueba\n",
        "test_mask[test_indices] = True\n",
        "\n",
        "# --- ¡Guardamos las máscaras en nuestro grafo! ---\n",
        "data['cliente', 'hizo_compra_en', 'comercio'].train_mask = train_mask\n",
        "data['cliente', 'hizo_compra_en', 'comercio'].test_mask = test_mask\n",
        "\n",
        "print(\"¡Datos divididos con éxito!\")\n",
        "print(\"==============================\")\n",
        "print(f\"Transacciones de Entrenamiento: {train_mask.sum().item()}\")\n",
        "print(f\"Transacciones de Prueba: {test_mask.sum().item()}\")\n",
        "print(\"\\n¡Nuestro grafo ahora tiene máscaras de entrenamiento y prueba!\")\n",
        "print(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZa1eHruzd1j",
        "outputId": "7ce19cbb-de1a-4714-edd7-4f25b715a8e4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡Datos divididos con éxito!\n",
            "==============================\n",
            "Transacciones de Entrenamiento: 800\n",
            "Transacciones de Prueba: 200\n",
            "\n",
            "¡Nuestro grafo ahora tiene máscaras de entrenamiento y prueba!\n",
            "HeteroData(\n",
            "  cliente={ num_nodes=636 },\n",
            "  comercio={ num_nodes=651 },\n",
            "  (cliente, hizo_compra_en, comercio)={\n",
            "    edge_index=[2, 1000],\n",
            "    edge_attr=[1000, 1],\n",
            "    y=[1000],\n",
            "    train_mask=[1000],\n",
            "    test_mask=[1000],\n",
            "  }\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv, to_hetero, Linear\n",
        "import torch.nn as nn\n",
        "\n",
        "# --- Paso 1: Crear \"features\" (características) iniciales ---\n",
        "# Nuestros nodos no tienen características (edad, etc.), solo son IDs.\n",
        "# Vamos a crear un vector de 16 características ALEATORIAS para cada nodo.\n",
        "# El modelo \"aprenderá\" a convertir esto en algo útil.\n",
        "data['cliente'].x = torch.randn(data['cliente'].num_nodes, 16)\n",
        "data['comercio'].x = torch.randn(data['comercio'].num_nodes, 16)\n",
        "\n",
        "\n",
        "# --- Paso 2: Definir la arquitectura del GNN ---\n",
        "# (El que aprende los perfiles de los nodos)\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        # Usaremos SAGEConv, que es muy potente y estándar en la industria\n",
        "        # -1 significa que infiera los tamaños de entrada\n",
        "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
        "        self.conv2 = SAGEConv((-1, -1), hidden_channels)\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict):\n",
        "        # Aplicamos la primera capa de convolución\n",
        "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
        "        x_dict = {key: x.relu() for key, x in x_dict.items()} # Función de activación\n",
        "\n",
        "        # Aplicamos la segunda capa de convolución\n",
        "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
        "\n",
        "        return x_dict # Devolvemos los perfiles (embeddings) de nodo finales\n",
        "\n",
        "# --- Paso 3: Definir el \"Clasificador de Conexiones\" ---\n",
        "# (El que mira los perfiles y decide si es fraude)\n",
        "class EdgeClassifier(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        # Tomará (perfil_cliente + perfil_comercio) = 64 + 64 = 128\n",
        "        # y lo pasará por una red neuronal simple (MLP)\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            Linear(2 * hidden_channels, hidden_channels),\n",
        "            nn.ReLU(),\n",
        "            Linear(hidden_channels, 2) # 2 clases: 0 (No Fraude), 1 (Fraude)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_dict, edge_index):\n",
        "        # Juntar los perfiles de los nodos de cada conexión\n",
        "        src_emb = x_dict['cliente'][edge_index[0]]\n",
        "        dest_emb = x_dict['comercio'][edge_index[1]]\n",
        "\n",
        "        # Concatenarlos (pegarlos uno al lado del otro)\n",
        "        edge_emb = torch.cat([src_emb, dest_emb], dim=1)\n",
        "\n",
        "        # Clasificar\n",
        "        return self.mlp(edge_emb)\n",
        "\n",
        "# --- Paso 4: Unir todo en un Modelo Completo ---\n",
        "class FraudGNN(torch.nn.Module):\n",
        "    def __init__(self, gnn_hidden_channels=64, clf_hidden_channels=64):\n",
        "        super().__init__()\n",
        "        # El GNN que aprende los perfiles de los nodos\n",
        "        self.gnn = GNN(gnn_hidden_channels)\n",
        "        # Usamos \"to_hetero\" para que nuestro GNN simple (SAGEConv)\n",
        "        # funcione en nuestro grafo complejo (HeteroData)\n",
        "        self.gnn = to_hetero(self.gnn, data.metadata(), aggr='sum')\n",
        "\n",
        "        # El clasificador que predice las conexiones\n",
        "        self.classifier = EdgeClassifier(gnn_hidden_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        # 1. Obtener perfiles de nodos del GNN\n",
        "        x_dict = self.gnn(data.x_dict, data.edge_index_dict)\n",
        "\n",
        "        # 2. Clasificar las conexiones (edges)\n",
        "        edge_label_index = data['cliente', 'hizo_compra_en', 'comercio'].edge_index\n",
        "        pred = self.classifier(x_dict, edge_label_index)\n",
        "\n",
        "        return pred\n",
        "\n",
        "# --- Paso 5: Inicializar el modelo ---\n",
        "model = FraudGNN(gnn_hidden_channels=64)\n",
        "\n",
        "print(\"¡Modelo GNN + Clasificador creado con éxito!\")\n",
        "print(\"============================================\")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "rJtohttKz9lb",
        "outputId": "2fee8b82-27d9-4489-94e9-4c1a5c80c303"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TraceError",
          "evalue": "Proxy object cannot be iterated. This can be attempted when the Proxy is used in a loop or as a *args or **kwargs function argument. See the torch.fx docs on pytorch.org for a more detailed explanation of what types of control flow can be traced, and check out the Proxy docstring for help troubleshooting Proxy iteration errors",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTraceError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2072791645.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m# --- Paso 5: Inicializar el modelo ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFraudGNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgnn_hidden_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"¡Modelo GNN + Clasificador creado con éxito!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2072791645.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, gnn_hidden_channels, clf_hidden_channels)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# Usamos \"to_hetero\" para que nuestro GNN simple (SAGEConv)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# funcione en nuestro grafo complejo (HeteroData)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_hetero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# El clasificador que predice las conexiones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/to_hetero_transformer.py\u001b[0m in \u001b[0;36mto_hetero\u001b[0;34m(module, metadata, aggr, input_map, debug)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mtransformation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \"\"\"\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mtransformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mToHeteroTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/to_hetero_transformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, module, metadata, aggr, input_map, debug)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     ):\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/fx.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, module, input_map, debug)\u001b[0m\n\u001b[1;32m     73\u001b[0m     ):\n\u001b[1;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msymbolic_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/fx.py\u001b[0m in \u001b[0;36msymbolic_trace\u001b[0;34m(module, concrete_args)\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mGraphModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTracer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcrete_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/fx.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(self, root, concrete_args)\u001b[0m\n\u001b[1;32m    368\u001b[0m                                        self._autowrap_function_ids)\n\u001b[1;32m    369\u001b[0m                 self.create_node(\n\u001b[0;32m--> 370\u001b[0;31m                     \u001b[0;34m'output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m                     type_expr=fn.__annotations__.get('return', None))\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2072791645.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_dict, edge_index_dict)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Aplicamos la primera capa de convolución\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mx_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m# Función de activación\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Aplicamos la segunda capa de convolución\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/fx/proxy.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[index]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__abs__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/fx/proxy.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0minformation\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mnode\u001b[0m \u001b[0musing\u001b[0m \u001b[0mcreate_node\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mchoose\u001b[0m \u001b[0mto\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0man\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \"\"\"\n\u001b[0;32m--> 399\u001b[0;31m         raise TraceError(\n\u001b[0m\u001b[1;32m    400\u001b[0m             \u001b[0;34m\"Proxy object cannot be iterated. This can be \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;34m\"attempted when the Proxy is used in a loop or\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTraceError\u001b[0m: Proxy object cannot be iterated. This can be attempted when the Proxy is used in a loop or as a *args or **kwargs function argument. See the torch.fx docs on pytorch.org for a more detailed explanation of what types of control flow can be traced, and check out the Proxy docstring for help troubleshooting Proxy iteration errors"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv, to_hetero, Linear\n",
        "import torch.nn as nn\n",
        "\n",
        "# --- Paso 1: Crear \"features\" (características) iniciales ---\n",
        "# (Esto se queda igual)\n",
        "data['cliente'].x = torch.randn(data['cliente'].num_nodes, 16)\n",
        "data['comercio'].x = torch.randn(data['comercio'].num_nodes, 16)\n",
        "\n",
        "\n",
        "# --- Paso 2: Definir la arquitectura del GNN ---\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
        "        self.conv2 = SAGEConv((-1, -1), hidden_channels)\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict):\n",
        "        # Aplicamos la primera capa de convolución\n",
        "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
        "\n",
        "        # ------------------- ¡AQUÍ ESTÁ EL ARREGLO! -------------------\n",
        "        # No podemos usar una \"comprensión de diccionario\" porque torch.fx no la entiende.\n",
        "        # Lo reemplazamos con un bucle 'for' normal.\n",
        "        out_dict = {}\n",
        "        for key, x in x_dict.items():\n",
        "            out_dict[key] = x.relu()  # Aplicamos ReLU a cada tensor\n",
        "        x_dict = out_dict # Reemplazamos el diccionario original\n",
        "        # ------------------- ¡FIN DEL ARREGLO! -------------------\n",
        "\n",
        "        # Aplicamos la segunda capa de convolución\n",
        "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
        "\n",
        "        return x_dict # Devolvemos los perfiles (embeddings) de nodo finales\n",
        "\n",
        "# --- Paso 3: Definir el \"Clasificador de Conexiones\" ---\n",
        "# (Esto se queda igual)\n",
        "class EdgeClassifier(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            Linear(2 * hidden_channels, hidden_channels),\n",
        "            nn.ReLU(),\n",
        "            Linear(hidden_channels, 2) # 2 clases: 0 (No Fraude), 1 (Fraude)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_dict, edge_index):\n",
        "        src_emb = x_dict['cliente'][edge_index[0]]\n",
        "        dest_emb = x_dict['comercio'][edge_index[1]]\n",
        "\n",
        "        edge_emb = torch.cat([src_emb, dest_emb], dim=1)\n",
        "\n",
        "        return self.mlp(edge_emb)\n",
        "\n",
        "# --- Paso 4: Unir todo en un Modelo Completo ---\n",
        "# (Esto se queda igual)\n",
        "class FraudGNN(torch.nn.Module):\n",
        "    def __init__(self, gnn_hidden_channels=64, clf_hidden_channels=64):\n",
        "        super().__init__()\n",
        "        self.gnn = GNN(gnn_hidden_channels)\n",
        "        self.gnn = to_hetero(self.gnn, data.metadata(), aggr='sum')\n",
        "        self.classifier = EdgeClassifier(gnn_hidden_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x_dict = self.gnn(data.x_dict, data.edge_index_dict)\n",
        "        edge_label_index = data['cliente', 'hizo_compra_en', 'comercio'].edge_index\n",
        "        pred = self.classifier(x_dict, edge_label_index)\n",
        "        return pred\n",
        "\n",
        "# --- Paso 5: Inicializar el modelo ---\n",
        "model = FraudGNN(gnn_hidden_channels=64) # ¡Esta es la línea que fallaba!\n",
        "\n",
        "print(\"¡Modelo GNN + Clasificador creado con éxito!\")\n",
        "print(\"============================================\")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "nF-NpE2I0eLF",
        "outputId": "f1027641-81d8-4fb4-ac73-5cee305bc0e3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TraceError",
          "evalue": "Proxy object cannot be iterated. This can be attempted when the Proxy is used in a loop or as a *args or **kwargs function argument. See the torch.fx docs on pytorch.org for a more detailed explanation of what types of control flow can be traced, and check out the Proxy docstring for help troubleshooting Proxy iteration errors",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTraceError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2081282410.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# --- Paso 5: Inicializar el modelo ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFraudGNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgnn_hidden_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ¡Esta es la línea que fallaba!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"¡Modelo GNN + Clasificador creado con éxito!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2081282410.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, gnn_hidden_channels, clf_hidden_channels)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgnn_hidden_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_hetero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEdgeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgnn_hidden_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/to_hetero_transformer.py\u001b[0m in \u001b[0;36mto_hetero\u001b[0;34m(module, metadata, aggr, input_map, debug)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mtransformation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \"\"\"\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mtransformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mToHeteroTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/to_hetero_transformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, module, metadata, aggr, input_map, debug)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     ):\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/fx.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, module, input_map, debug)\u001b[0m\n\u001b[1;32m     73\u001b[0m     ):\n\u001b[1;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msymbolic_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/fx.py\u001b[0m in \u001b[0;36msymbolic_trace\u001b[0;34m(module, concrete_args)\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mGraphModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTracer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcrete_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/fx.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(self, root, concrete_args)\u001b[0m\n\u001b[1;32m    368\u001b[0m                                        self._autowrap_function_ids)\n\u001b[1;32m    369\u001b[0m                 self.create_node(\n\u001b[0;32m--> 370\u001b[0;31m                     \u001b[0;34m'output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m                     type_expr=fn.__annotations__.get('return', None))\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2081282410.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_dict, edge_index_dict)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Lo reemplazamos con un bucle 'for' normal.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mout_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mout_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Aplicamos ReLU a cada tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mx_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_dict\u001b[0m \u001b[0;31m# Reemplazamos el diccionario original\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/fx/proxy.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[index]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__abs__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/fx/proxy.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0minformation\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mnode\u001b[0m \u001b[0musing\u001b[0m \u001b[0mcreate_node\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mchoose\u001b[0m \u001b[0mto\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0man\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \"\"\"\n\u001b[0;32m--> 399\u001b[0;31m         raise TraceError(\n\u001b[0m\u001b[1;32m    400\u001b[0m             \u001b[0;34m\"Proxy object cannot be iterated. This can be \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;34m\"attempted when the Proxy is used in a loop or\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTraceError\u001b[0m: Proxy object cannot be iterated. This can be attempted when the Proxy is used in a loop or as a *args or **kwargs function argument. See the torch.fx docs on pytorch.org for a more detailed explanation of what types of control flow can be traced, and check out the Proxy docstring for help troubleshooting Proxy iteration errors"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv, to_hetero, Linear\n",
        "import torch.nn as nn\n",
        "\n",
        "# --- Paso 1: Crear \"features\" (características) iniciales ---\n",
        "# (Esto se queda igual, pero lo ponemos para que la celda sea completa)\n",
        "# Nuestros nodos no tienen características, así que creamos un vector aleatorio\n",
        "# El modelo aprenderá a que este vector tenga sentido.\n",
        "data['cliente'].x = torch.randn(data['cliente'].num_nodes, 16)\n",
        "data['comercio'].x = torch.randn(data['comercio'].num_nodes, 16)\n",
        "\n",
        "\n",
        "# --- Paso 2: Definir el \"Clasificador de Conexiones\" ---\n",
        "# (Este se queda igual, solo lo muevo aquí)\n",
        "class EdgeClassifier(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        # Red neuronal simple (MLP)\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            Linear(2 * hidden_channels, hidden_channels), # 2*hidden_channels porque concatenamos (cliente + comercio)\n",
        "            nn.ReLU(),\n",
        "            Linear(hidden_channels, 2) # 2 clases: 0 (No Fraude), 1 (Fraude)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_dict, edge_index):\n",
        "        # Tomar los perfiles de los nodos de la conexión\n",
        "        src_emb = x_dict['cliente'][edge_index[0]]\n",
        "        dest_emb = x_dict['comercio'][edge_index[1]]\n",
        "\n",
        "        # Concatenarlos (pegarlos)\n",
        "        edge_emb = torch.cat([src_emb, dest_emb], dim=1)\n",
        "\n",
        "        # Clasificar\n",
        "        return self.mlp(edge_emb)\n",
        "\n",
        "# --- Paso 3: ¡LA NUEVA ARQUITECTURA (LA CORRECTA!) ---\n",
        "class FraudGNN(torch.nn.Module):\n",
        "    def __init__(self, gnn_hidden_channels=64, clf_hidden_channels=64):\n",
        "        super().__init__()\n",
        "\n",
        "        # ¡AQUÍ ESTÁ LA MAGIA!\n",
        "        # 1. Definimos el \"stack\" del GNN como una secuencia simple\n",
        "        gnn_stack = nn.Sequential(\n",
        "            # SAGEConv((-1, -1)...) significa que acepta cualquier tamaño de entrada\n",
        "            SAGEConv((-1, -1), gnn_hidden_channels),\n",
        "            nn.ReLU(),\n",
        "            SAGEConv((-1, -1), gnn_hidden_channels),\n",
        "        )\n",
        "\n",
        "        # 2. ¡Envolvemos el stack simple con to_hetero!\n",
        "        # Esto lo convierte en un GNN que entiende nuestro grafo\n",
        "        self.gnn = to_hetero(gnn_stack, data.metadata(), aggr='sum')\n",
        "\n",
        "        # 3. El clasificador sigue igual\n",
        "        self.classifier = EdgeClassifier(gnn_hidden_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        # 1. Obtener perfiles de nodos del GNN (¡ahora funciona!)\n",
        "        x_dict = self.gnn(data.x_dict, data.edge_index_dict)\n",
        "\n",
        "        # 2. Clasificar las conexiones (edges)\n",
        "        edge_label_index = data['cliente', 'hizo_compra_en', 'comercio'].edge_index\n",
        "        pred = self.classifier(x_dict, edge_label_index)\n",
        "\n",
        "        return pred\n",
        "\n",
        "# --- Paso 4: Inicializar el modelo ---\n",
        "model = FraudGNN(gnn_hidden_channels=64) # ¡Esta es la línea que fallaba!\n",
        "\n",
        "print(\"¡Modelo GNN + Clasificador creado con éxito!\")\n",
        "print(\"============================================\")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "njgGria905he",
        "outputId": "5e4915fd-7174-489e-fa6b-8c877477f88a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/to_hetero_transformer.py:151: UserWarning: There exist node types ({'cliente'}) whose representations do not get updated during message passing as they do not occur as destination type in any edge type. This may lead to unexpected behavior.\n",
            "  self.validate()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot generate a graph node '_1' for type 'cliente' since it does not exist. Please make sure that all node types get updated during message passing.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1841155315.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# --- Paso 4: Inicializar el modelo ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFraudGNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgnn_hidden_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ¡Esta es la línea que fallaba!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"¡Modelo GNN + Clasificador creado con éxito!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1841155315.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, gnn_hidden_channels, clf_hidden_channels)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# 2. ¡Envolvemos el stack simple con to_hetero!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# Esto lo convierte en un GNN que entiende nuestro grafo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_hetero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgnn_stack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# 3. El clasificador sigue igual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/to_hetero_transformer.py\u001b[0m in \u001b[0;36mto_hetero\u001b[0;34m(module, metadata, aggr, input_map, debug)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \"\"\"\n\u001b[1;32m    119\u001b[0m     \u001b[0mtransformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mToHeteroTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/fx.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mis_global_pooling_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'call_global_pooling_module'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# Remove all unused nodes in the computation graph, i.e., all nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/to_hetero_transformer.py\u001b[0m in \u001b[0;36mcall_module\u001b[0;34m(self, node, target, name)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minserting_after\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_edge_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_args_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             out = self.graph.create_node('call_module',\n\u001b[1;32m    296\u001b[0m                                          \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{target}.{key2str(key)}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/to_hetero_transformer.py\u001b[0m in \u001b[0;36mmap_args_kwargs\u001b[0;34m(self, node, key)\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_recurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_recurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/to_hetero_transformer.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_recurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_recurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/to_hetero_transformer.py\u001b[0m in \u001b[0;36m_recurse\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    402\u001b[0m                     )\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m                     raise ValueError(f\"Cannot generate a graph node '{node}' \"\n\u001b[0m\u001b[1;32m    405\u001b[0m                                      \u001b[0;34mf\"for type '{key}' since it does not \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                                      \u001b[0;34mf\"exist. Please make sure that all \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot generate a graph node '_1' for type 'cliente' since it does not exist. Please make sure that all node types get updated during message passing."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- MÓDULO 3 (CORREGIDO) - ¡Volver a ejecutar! ---\n",
        "import torch\n",
        "from torch_geometric.data import HeteroData\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# --- 1. Crear el contenedor ---\n",
        "data = HeteroData()\n",
        "\n",
        "# --- 2. Crear los Mapeos de Índices (igual que antes) ---\n",
        "customer_encoder = LabelEncoder()\n",
        "merchant_encoder = LabelEncoder()\n",
        "df_master['customer_idx'] = customer_encoder.fit_transform(df_master['CustomerID'])\n",
        "df_master['merchant_idx'] = merchant_encoder.fit_transform(df_master['MerchantID'])\n",
        "\n",
        "# --- 3. Cargar los NODOS (igual que antes) ---\n",
        "data['cliente'].num_nodes = len(df_master['customer_idx'].unique())\n",
        "data['comercio'].num_nodes = len(df_master['merchant_idx'].unique())\n",
        "\n",
        "# --- 4. Cargar las CONEXIONES 'hacia adelante' (igual que antes) ---\n",
        "source = torch.tensor(df_master['customer_idx'].values, dtype=torch.long)\n",
        "destination = torch.tensor(df_master['merchant_idx'].values, dtype=torch.long)\n",
        "edge_index = torch.stack([source, destination])\n",
        "data['cliente', 'hizo_compra_en', 'comercio'].edge_index = edge_index\n",
        "\n",
        "# --- 5. Cargar Features y Labels en la conexión 'hacia adelante' (igual que antes) ---\n",
        "edge_features = torch.tensor(df_master['Amount'].values, dtype=torch.float).view(-1, 1)\n",
        "labels = torch.tensor(df_master['FraudIndicator'].values, dtype=torch.long)\n",
        "data['cliente', 'hizo_compra_en', 'comercio'].edge_attr = edge_features\n",
        "data['cliente', 'hizo_compra_en', 'comercio'].y = labels\n",
        "\n",
        "# --- ¡AQUÍ ESTÁ LA NUEVA MAGIA! (EL ARREGLO) ---\n",
        "# Creamos las conexiones 'de regreso' (comercio -> cliente)\n",
        "# ¡Son los mismos datos, pero invertidos!\n",
        "rev_edge_index = torch.stack([destination, source]) # ¡Al revés!\n",
        "\n",
        "# Las añadimos al grafo con un nuevo nombre de conexión\n",
        "data['comercio', 'es_comercio_de', 'cliente'].edge_index = rev_edge_index\n",
        "# También copiamos las features (el 'Amount') a esta conexión\n",
        "data['comercio', 'es_comercio_de', 'cliente'].edge_attr = edge_features\n",
        "# ¡OJO! No ponemos 'y' (labels) aquí, porque solo predecimos la conexión de \"ida\".\n",
        "\n",
        "print(\"¡Grafo Heterogéneo DE DOBLE VÍA creado con éxito!\")\n",
        "print(\"=================================================\")\n",
        "print(data)\n",
        "print(f\"¿Es un grafo válido? {data.validate()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILtFyxik1Kze",
        "outputId": "a39d1587-e580-461a-c844-e377638b7356"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡Grafo Heterogéneo DE DOBLE VÍA creado con éxito!\n",
            "=================================================\n",
            "HeteroData(\n",
            "  cliente={ num_nodes=636 },\n",
            "  comercio={ num_nodes=651 },\n",
            "  (cliente, hizo_compra_en, comercio)={\n",
            "    edge_index=[2, 1000],\n",
            "    edge_attr=[1000, 1],\n",
            "    y=[1000],\n",
            "  },\n",
            "  (comercio, es_comercio_de, cliente)={\n",
            "    edge_index=[2, 1000],\n",
            "    edge_attr=[1000, 1],\n",
            "  }\n",
            ")\n",
            "¿Es un grafo válido? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- MÓDULO 3 (CORREGIDO) - ¡Volver a ejecutar! ---\n",
        "import torch\n",
        "from torch_geometric.data import HeteroData\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# --- 1. Crear el contenedor ---\n",
        "data = HeteroData()\n",
        "\n",
        "# --- 2. Crear los Mapeos de Índices (igual que antes) ---\n",
        "customer_encoder = LabelEncoder()\n",
        "merchant_encoder = LabelEncoder()\n",
        "df_master['customer_idx'] = customer_encoder.fit_transform(df_master['CustomerID'])\n",
        "df_master['merchant_idx'] = merchant_encoder.fit_transform(df_master['MerchantID'])\n",
        "\n",
        "# --- 3. Cargar los NODOS (igual que antes) ---\n",
        "data['cliente'].num_nodes = len(df_master['customer_idx'].unique())\n",
        "data['comercio'].num_nodes = len(df_master['merchant_idx'].unique())\n",
        "\n",
        "# --- 4. Cargar las CONEXIONES 'hacia adelante' (igual que antes) ---\n",
        "source = torch.tensor(df_master['customer_idx'].values, dtype=torch.long)\n",
        "destination = torch.tensor(df_master['merchant_idx'].values, dtype=torch.long)\n",
        "edge_index = torch.stack([source, destination])\n",
        "data['cliente', 'hizo_compra_en', 'comercio'].edge_index = edge_index\n",
        "\n",
        "# --- 5. Cargar Features y Labels en la conexión 'hacia adelante' (igual que antes) ---\n",
        "edge_features = torch.tensor(df_master['Amount'].values, dtype=torch.float).view(-1, 1)\n",
        "labels = torch.tensor(df_master['FraudIndicator'].values, dtype=torch.long)\n",
        "data['cliente', 'hizo_compra_en', 'comercio'].edge_attr = edge_features\n",
        "data['cliente', 'hizo_compra_en', 'comercio'].y = labels\n",
        "\n",
        "# --- ¡AQUÍ ESTÁ LA NUEVA MAGIA! (EL ARREGLO) ---\n",
        "# Creamos las conexiones 'de regreso' (comercio -> cliente)\n",
        "# ¡Son los mismos datos, pero invertidos!\n",
        "rev_edge_index = torch.stack([destination, source]) # ¡Al revés!\n",
        "\n",
        "# Las añadimos al grafo con un nuevo nombre de conexión\n",
        "data['comercio', 'es_comercio_de', 'cliente'].edge_index = rev_edge_index\n",
        "# También copiamos las features (el 'Amount') a esta conexión\n",
        "data['comercio', 'es_comercio_de', 'cliente'].edge_attr = edge_features\n",
        "# ¡OJO! No ponemos 'y' (labels) aquí, porque solo predecimos la conexión de \"ida\".\n",
        "\n",
        "print(\"¡Grafo Heterogéneo DE DOBLE VÍA creado con éxito!\")\n",
        "print(\"=================================================\")\n",
        "print(data)\n",
        "print(f\"¿Es un grafo válido? {data.validate()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0X5Vxdf1pP1",
        "outputId": "7109def7-be60-49c4-bdc3-68ca79f60f2b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡Grafo Heterogéneo DE DOBLE VÍA creado con éxito!\n",
            "=================================================\n",
            "HeteroData(\n",
            "  cliente={ num_nodes=636 },\n",
            "  comercio={ num_nodes=651 },\n",
            "  (cliente, hizo_compra_en, comercio)={\n",
            "    edge_index=[2, 1000],\n",
            "    edge_attr=[1000, 1],\n",
            "    y=[1000],\n",
            "  },\n",
            "  (comercio, es_comercio_de, cliente)={\n",
            "    edge_index=[2, 1000],\n",
            "    edge_attr=[1000, 1],\n",
            "  }\n",
            ")\n",
            "¿Es un grafo válido? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Tenemos 1000 conexiones (edges)\n",
        "num_edges = data['cliente', 'hizo_compra_en', 'comercio'].num_edges\n",
        "\n",
        "# Creamos un array de índices, de 0 a 999\n",
        "edge_indices = torch.arange(num_edges)\n",
        "\n",
        "# ¡Usamos sklearn para dividir los ÍNDICES!\n",
        "# Dividimos 80% para entrenar, 20% para probar\n",
        "# random_state=42 es para que la división sea siempre la misma y podamos repetir el experimento\n",
        "train_indices, test_indices = train_test_split(\n",
        "    edge_indices,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# --- Ahora creamos \"Máscaras\" (Masks) ---\n",
        "# PyG ama las máscaras. Son un array de True/False del tamaño de los edges\n",
        "train_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
        "test_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
        "\n",
        "# Ponemos 'True' en las posiciones que pertenecen al set de entrenamiento\n",
        "train_mask[train_indices] = True\n",
        "# Ponemos 'True' en las posiciones que pertenecen al set de prueba\n",
        "test_mask[test_indices] = True\n",
        "\n",
        "# --- ¡Guardamos las máscaras en nuestro grafo! ---\n",
        "data['cliente', 'hizo_compra_en', 'comercio'].train_mask = train_mask\n",
        "data['cliente', 'hizo_compra_en', 'comercio'].test_mask = test_mask\n",
        "\n",
        "print(\"¡Datos divididos con éxito!\")\n",
        "print(\"==============================\")\n",
        "print(f\"Transacciones de Entrenamiento: {train_mask.sum().item()}\")\n",
        "print(f\"Transacciones de Prueba: {test_mask.sum().item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h3UR99i1sFm",
        "outputId": "e48b4524-6826-4672-b53f-95dbeb0666ae"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡Datos divididos con éxito!\n",
            "==============================\n",
            "Transacciones de Entrenamiento: 800\n",
            "Transacciones de Prueba: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv, to_hetero, Linear\n",
        "import torch.nn as nn\n",
        "\n",
        "# --- Paso 1: Crear \"features\" (características) iniciales ---\n",
        "# (Esto se queda igual, pero lo ponemos para que la celda sea completa)\n",
        "# Nuestros nodos no tienen características, así que creamos un vector aleatorio\n",
        "# El modelo aprenderá a que este vector tenga sentido.\n",
        "data['cliente'].x = torch.randn(data['cliente'].num_nodes, 16)\n",
        "data['comercio'].x = torch.randn(data['comercio'].num_nodes, 16)\n",
        "\n",
        "\n",
        "# --- Paso 2: Definir el \"Clasificador de Conexiones\" ---\n",
        "class EdgeClassifier(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        # Red neuronal simple (MLP)\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            Linear(2 * hidden_channels, hidden_channels), # 2*hidden_channels porque concatenamos (cliente + comercio)\n",
        "            nn.ReLU(),\n",
        "            Linear(hidden_channels, 2) # 2 clases: 0 (No Fraude), 1 (Fraude)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_dict, edge_index):\n",
        "        # Tomar los perfiles de los nodos de la conexión\n",
        "        src_emb = x_dict['cliente'][edge_index[0]]\n",
        "        dest_emb = x_dict['comercio'][edge_index[1]]\n",
        "\n",
        "        # Concatenarlos (pegarlos)\n",
        "        edge_emb = torch.cat([src_emb, dest_emb], dim=1)\n",
        "\n",
        "        # Clasificar\n",
        "        return self.mlp(edge_emb)\n",
        "\n",
        "# --- Paso 3: ¡LA ARQUITECTURA CORRECTA! ---\n",
        "class FraudGNN(torch.nn.Module):\n",
        "    def __init__(self, gnn_hidden_channels=64, clf_hidden_channels=64):\n",
        "        super().__init__()\n",
        "\n",
        "        # 1. Definimos el \"stack\" del GNN como una secuencia simple\n",
        "        gnn_stack = nn.Sequential(\n",
        "            SAGEConv((-1, -1), gnn_hidden_channels),\n",
        "            nn.ReLU(),\n",
        "            SAGEConv((-1, -1), gnn_hidden_channels),\n",
        "        )\n",
        "\n",
        "        # 2. ¡Envolvemos el stack simple con to_hetero!\n",
        "        # ¡Esto SÍ FUNCIONARÁ ahora que el grafo es de doble vía!\n",
        "        self.gnn = to_hetero(gnn_stack, data.metadata(), aggr='sum')\n",
        "\n",
        "        # 3. El clasificador sigue igual\n",
        "        self.classifier = EdgeClassifier(gnn_hidden_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        # 1. Obtener perfiles de nodos del GNN (¡ahora funciona!)\n",
        "        x_dict = self.gnn(data.x_dict, data.edge_index_dict)\n",
        "\n",
        "        # 2. Clasificar las conexiones (edges)\n",
        "        edge_label_index = data['cliente', 'hizo_compra_en', 'comercio'].edge_index\n",
        "        pred = self.classifier(x_dict, edge_label_index)\n",
        "\n",
        "        return pred\n",
        "\n",
        "# --- Paso 4: Inicializar el modelo ---\n",
        "model = FraudGNN(gnn_hidden_channels=64) # ¡Esta es la línea que fallaba!\n",
        "\n",
        "print(\"¡Modelo GNN + Clasificador creado con éxito!\")\n",
        "print(\"============================================\")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfmG_fV91vHL",
        "outputId": "1d55ce7f-1c2c-4f6f-9e63-1d13bc813c60"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡Modelo GNN + Clasificador creado con éxito!\n",
            "============================================\n",
            "FraudGNN(\n",
            "  (gnn): GraphModule(\n",
            "    (0): ModuleDict(\n",
            "      (cliente__hizo_compra_en__comercio): SAGEConv((-1, -1), 64, aggr=mean)\n",
            "      (comercio__es_comercio_de__cliente): SAGEConv((-1, -1), 64, aggr=mean)\n",
            "    )\n",
            "    (1): ModuleDict(\n",
            "      (cliente): ReLU()\n",
            "      (comercio): ReLU()\n",
            "    )\n",
            "    (2): ModuleDict(\n",
            "      (cliente__hizo_compra_en__comercio): SAGEConv((-1, -1), 64, aggr=mean)\n",
            "      (comercio__es_comercio_de__cliente): SAGEConv((-1, -1), 64, aggr=mean)\n",
            "    )\n",
            "  )\n",
            "  (classifier): EdgeClassifier(\n",
            "    (mlp): Sequential(\n",
            "      (0): Linear(128, 64, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(64, 2, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Módulo 6: ¡El Entrenamiento! ---\n",
        "\n",
        "# 1. Mover todo a la CPU (¡buena práctica!)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "data = data.to(device)\n",
        "\n",
        "# 2. Definir el \"profesor\" (Función de Pérdida)\n",
        "# CrossEntropyLoss es perfecto para clasificación binaria (0 o 1)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# 3. Definir el \"mecanismo\" de aprendizaje (Optimizador)\n",
        "# Adam es el estándar de la industria. Le decimos que ajuste las \"perillas\" (parámetros) del modelo\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# --- 4. Preparar las etiquetas (labels) que usaremos ---\n",
        "# Sacamos las etiquetas de la conexión que queremos predecir\n",
        "labels = data['cliente', 'hizo_compra_en', 'comercio'].y\n",
        "# Sacamos la máscara de entrenamiento\n",
        "train_mask = data['cliente', 'hizo_compra_en', 'comercio'].train_mask\n",
        "\n",
        "# --- 5. ¡El Bucle de Entrenamiento! ---\n",
        "print(\"¡Comenzando el entrenamiento del modelo GNN!\")\n",
        "print(\"==========================================\")\n",
        "\n",
        "model.train() # Poner el modelo en modo \"entrenamiento\"\n",
        "\n",
        "for epoch in range(101): # 100 rondas de estudio\n",
        "\n",
        "    # \"Borramos la pizarra\" de los errores anteriores\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Hacemos una predicción con TODOS los datos\n",
        "    out = model(data)\n",
        "\n",
        "    # ¡Calculamos el error (loss) SÓLO en los datos de entrenamiento!\n",
        "    # Comparamos las predicciones (out) de la máscara de entrenamiento\n",
        "    # con las respuestas correctas (labels) de esa misma máscara\n",
        "    loss = criterion(out[train_mask], labels[train_mask])\n",
        "\n",
        "    # Calculamos cómo ajustar las perillas (backpropagation)\n",
        "    loss.backward()\n",
        "\n",
        "    # Aplicamos los ajustes\n",
        "    optimizer.step()\n",
        "\n",
        "    # Imprimimos el progreso\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Época {epoch:03d} | Pérdida (Loss): {loss.item():.4f}\")\n",
        "\n",
        "print(\"\\n¡Entrenamiento completado!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "T534O-rj2QfR",
        "outputId": "cb3c1d44-8789-4471-f90a-8bfa3a7ea19f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡Comenzando el entrenamiento del modelo GNN!\n",
            "==========================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "forward() takes 2 positional arguments but 3 were given",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1950005613.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Hacemos una predicción con TODOS los datos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# ¡Calculamos el error (loss) SÓLO en los datos de entrenamiento!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3624618018.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# 1. Obtener perfiles de nodos del GNN (¡ahora funciona!)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mx_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# 2. Clasificar las conexiones (edges)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_wrapped\u001b[0m  \u001b[0;31m# type: ignore[method-assign]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa: B904\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() takes 2 positional arguments but 3 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv, to_hetero, Linear\n",
        "import torch.nn as nn\n",
        "\n",
        "# --- Paso 1: Crear \"features\" (características) iniciales ---\n",
        "# (Esto se queda igual, pero lo ponemos para que la celda sea completa)\n",
        "data['cliente'].x = torch.randn(data['cliente'].num_nodes, 16)\n",
        "data['comercio'].x = torch.randn(data['comercio'].num_nodes, 16)\n",
        "\n",
        "# --- ¡AQUÍ ESTÁ EL ARREGLO! ---\n",
        "# 1. Creamos una clase \"mono-grafo\" simple.\n",
        "# Fíjate que el forward() toma 'x' y 'edge_index'.\n",
        "# ¡Esto es lo que 'to_hetero' necesita ver!\n",
        "class MonoGNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = SAGEConv((-1, -1), hidden_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # Esta es la arquitectura \"mono-grafo\"\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# 2. Definir el \"Clasificador de Conexiones\" (igual que antes)\n",
        "class EdgeClassifier(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            Linear(2 * hidden_channels, hidden_channels),\n",
        "            nn.ReLU(),\n",
        "            Linear(hidden_channels, 2)\n",
        "        )\n",
        "    def forward(self, x_dict, edge_index):\n",
        "        src_emb = x_dict['cliente'][edge_index[0]]\n",
        "        dest_emb = x_dict['comercio'][edge_index[1]]\n",
        "        edge_emb = torch.cat([src_emb, dest_emb], dim=1)\n",
        "        return self.mlp(edge_emb)\n",
        "\n",
        "# 3. ¡LA ARQUITECTURA CORRECTA!\n",
        "class FraudGNN(torch.nn.Module):\n",
        "    def __init__(self, gnn_hidden_channels=64):\n",
        "        super().__init__()\n",
        "\n",
        "        # 1. Creamos nuestra GNN \"mono\"\n",
        "        mono_gnn = MonoGNN(gnn_hidden_channels)\n",
        "\n",
        "        # 2. ¡Envolvemos el 'MonoGNN' con to_hetero!\n",
        "        # Esto SÍ FUNCIONARÁ\n",
        "        self.gnn = to_hetero(mono_gnn, data.metadata(), aggr='sum')\n",
        "\n",
        "        # 3. El clasificador sigue igual\n",
        "        self.classifier = EdgeClassifier(gnn_hidden_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        # 1. Obtener perfiles de nodos\n",
        "        # ¡Esta llamada ahora es correcta!\n",
        "        x_dict = self.gnn(data.x_dict, data.edge_index_dict)\n",
        "\n",
        "        # 2. Clasificar las conexiones\n",
        "        edge_label_index = data['cliente', 'hizo_compra_en', 'comercio'].edge_index\n",
        "        pred = self.classifier(x_dict, edge_label_index)\n",
        "\n",
        "        return pred\n",
        "\n",
        "# --- Paso 4: Inicializar el modelo ---\n",
        "model = FraudGNN(gnn_hidden_channels=64)\n",
        "\n",
        "print(\"¡Modelo GNN + Clasificador (¡Ahora sí!) creado con éxito!\")\n",
        "print(\"=========================================================\")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhEXsthL8n0N",
        "outputId": "eed65dc4-59e4-4e1e-c8a4-4db2e156ae22"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡Modelo GNN + Clasificador (¡Ahora sí!) creado con éxito!\n",
            "=========================================================\n",
            "FraudGNN(\n",
            "  (gnn): GraphModule(\n",
            "    (conv1): ModuleDict(\n",
            "      (cliente__hizo_compra_en__comercio): SAGEConv((-1, -1), 64, aggr=mean)\n",
            "      (comercio__es_comercio_de__cliente): SAGEConv((-1, -1), 64, aggr=mean)\n",
            "    )\n",
            "    (relu): ModuleDict(\n",
            "      (cliente): ReLU()\n",
            "      (comercio): ReLU()\n",
            "    )\n",
            "    (conv2): ModuleDict(\n",
            "      (cliente__hizo_compra_en__comercio): SAGEConv((-1, -1), 64, aggr=mean)\n",
            "      (comercio__es_comercio_de__cliente): SAGEConv((-1, -1), 64, aggr=mean)\n",
            "    )\n",
            "  )\n",
            "  (classifier): EdgeClassifier(\n",
            "    (mlp): Sequential(\n",
            "      (0): Linear(128, 64, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(64, 2, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Módulo 6: ¡El Entrenamiento! ---\n",
        "\n",
        "# 1. Mover todo a la CPU (¡buena práctica!)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "data = data.to(device)\n",
        "\n",
        "# 2. Definir el \"profesor\" (Función de Pérdida)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# 3. Definir el \"mecanismo\" de aprendizaje (Optimizador)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# --- 4. Preparar las etiquetas (labels) que usaremos ---\n",
        "labels = data['cliente', 'hizo_compra_en', 'comercio'].y\n",
        "train_mask = data['cliente', 'hizo_compra_en', 'comercio'].train_mask\n",
        "\n",
        "# --- 5. ¡El Bucle de Entrenamiento! ---\n",
        "print(\"¡Comenzando el entrenamiento del modelo GNN!\")\n",
        "print(\"==========================================\")\n",
        "\n",
        "model.train() # Poner el modelo en modo \"entrenamiento\"\n",
        "\n",
        "for epoch in range(101): # 100 rondas de estudio\n",
        "\n",
        "    # \"Borramos la pizarra\" de los errores anteriores\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Hacemos una predicción con TODOS los datos\n",
        "    out = model(data)\n",
        "\n",
        "    # ¡Calculamos el error (loss) SÓLO en los datos de entrenamiento!\n",
        "    loss = criterion(out[train_mask], labels[train_mask])\n",
        "\n",
        "    # Calculamos cómo ajustar las perillas (backpropagation)\n",
        "    loss.backward()\n",
        "\n",
        "    # Aplicamos los ajustes\n",
        "    optimizer.step()\n",
        "\n",
        "    # Imprimimos el progreso\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Época {epoch:03d} | Pérdida (Loss): {loss.item():.4f}\")\n",
        "\n",
        "print(\"\\n¡Entrenamiento completado!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYcGQOny8swC",
        "outputId": "ffb6e19e-3f1c-40ab-cefc-35671fbc242d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡Comenzando el entrenamiento del modelo GNN!\n",
            "==========================================\n",
            "Época 000 | Pérdida (Loss): 0.7819\n",
            "Época 010 | Pérdida (Loss): 0.1740\n",
            "Época 020 | Pérdida (Loss): 0.1007\n",
            "Época 030 | Pérdida (Loss): 0.0124\n",
            "Época 040 | Pérdida (Loss): 0.0003\n",
            "Época 050 | Pérdida (Loss): 0.0000\n",
            "Época 060 | Pérdida (Loss): 0.0000\n",
            "Época 070 | Pérdida (Loss): 0.0000\n",
            "Época 080 | Pérdida (Loss): 0.0000\n",
            "Época 090 | Pérdida (Loss): 0.0000\n",
            "Época 100 | Pérdida (Loss): 0.0000\n",
            "\n",
            "¡Entrenamiento completado!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Módulo 6: ¡El Entrenamiento! ---\n",
        "\n",
        "# 1. Mover todo a la CPU (¡buena práctica!)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "data = data.to(device)\n",
        "\n",
        "# 2. Definir el \"profesor\" (Función de Pérdida)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# 3. Definir el \"mecanismo\" de aprendizaje (Optimizador)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# --- 4. Preparar las etiquetas (labels) que usaremos ---\n",
        "labels = data['cliente', 'hizo_compra_en', 'comercio'].y\n",
        "train_mask = data['cliente', 'hizo_compra_en', 'comercio'].train_mask\n",
        "\n",
        "# --- 5. ¡El Bucle de Entrenamiento! ---\n",
        "print(\"¡Comenzando el entrenamiento del modelo GNN!\")\n",
        "print(\"==========================================\")\n",
        "\n",
        "model.train() # Poner el modelo en modo \"entrenamiento\"\n",
        "\n",
        "for epoch in range(101): # 100 rondas de estudio\n",
        "\n",
        "    # \"Borramos la pizarra\" de los errores anteriores\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Hacemos una predicción con TODOS los datos\n",
        "    out = model(data)\n",
        "\n",
        "    # ¡Calculamos el error (loss) SÓLO en los datos de entrenamiento!\n",
        "    loss = criterion(out[train_mask], labels[train_mask])\n",
        "\n",
        "    # Calculamos cómo ajustar las perillas (backpropagation)\n",
        "    loss.backward()\n",
        "\n",
        "    # Aplicamos los ajustes\n",
        "    optimizer.step()\n",
        "\n",
        "    # Imprimimos el progreso\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Época {epoch:03d} | Pérdida (Loss): {loss.item():.4f}\")\n",
        "\n",
        "print(\"\\n¡Entrenamiento completado!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl5wwrDV9AQA",
        "outputId": "885b7f33-c880-47ef-f7e4-2eedd1b47528"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡Comenzando el entrenamiento del modelo GNN!\n",
            "==========================================\n",
            "Época 000 | Pérdida (Loss): 0.0000\n",
            "Época 010 | Pérdida (Loss): 0.0037\n",
            "Época 020 | Pérdida (Loss): 0.0001\n",
            "Época 030 | Pérdida (Loss): 0.0000\n",
            "Época 040 | Pérdida (Loss): 0.0000\n",
            "Época 050 | Pérdida (Loss): 0.0000\n",
            "Época 060 | Pérdida (Loss): 0.0000\n",
            "Época 070 | Pérdida (Loss): 0.0000\n",
            "Época 080 | Pérdida (Loss): 0.0000\n",
            "Época 090 | Pérdida (Loss): 0.0000\n",
            "Época 100 | Pérdida (Loss): 0.0000\n",
            "\n",
            "¡Entrenamiento completado!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ¡Chequeo de Balance de Datos! ---\n",
        "\n",
        "print(\"--- Chequeo de Balance del Dataset ---\")\n",
        "\n",
        "# Sacamos todas las etiquetas (las 1000)\n",
        "labels = data['cliente', 'hizo_compra_en', 'comercio'].y\n",
        "total_transacciones = len(labels)\n",
        "\n",
        "# Como es 0 o 1, la suma nos da el total de 1s (fraudes)\n",
        "fraudes = labels.sum().item()\n",
        "no_fraudes = total_transacciones - fraudes\n",
        "\n",
        "print(f\"Total de transacciones: {total_transacciones}\")\n",
        "print(f\"Transacciones SIN Fraude (0): {no_fraudes}\")\n",
        "print(f\"Transacciones CON Fraude (1): {fraudes}\")\n",
        "print(f\"Porcentaje de Fraude: {(fraudes / total_transacciones) * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rf6dG03M9yCP",
        "outputId": "a34eb456-80ea-417e-ceed-65a8ce78bcf6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Chequeo de Balance del Dataset ---\n",
            "Total de transacciones: 1000\n",
            "Transacciones SIN Fraude (0): 955\n",
            "Transacciones CON Fraude (1): 45\n",
            "Porcentaje de Fraude: 4.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# --- Módulo 7: ¡La Evaluación! ---\n",
        "\n",
        "print(\"¡Evaluando el modelo en los datos de Prueba!\")\n",
        "print(\"==========================================\")\n",
        "\n",
        "# 1. Poner el modelo en modo \"evaluación\" (¡importante!)\n",
        "# Esto \"apaga\" cosas como el 'dropout' si lo tuviera.\n",
        "model.eval()\n",
        "\n",
        "# 2. Sacar las máscaras y etiquetas de prueba\n",
        "test_mask = data['cliente', 'hizo_compra_en', 'comercio'].test_mask\n",
        "labels = data['cliente', 'hizo_compra_en', 'comercio'].y\n",
        "\n",
        "# 3. Hacer predicciones (¡sin calcular gradientes!)\n",
        "with torch.no_grad(): # No necesitamos calcular cómo ajustar perillas aquí\n",
        "\n",
        "    # Hacemos la predicción con todos los datos\n",
        "    out = model(data)\n",
        "\n",
        "    # Nos quedamos SÓLO con las predicciones del set de prueba\n",
        "    pred_test = out[test_mask]\n",
        "\n",
        "    # ¿Cuál es la predicción final? La clase con el número más alto\n",
        "    # (El índice (0 o 1) con el valor más alto)\n",
        "    pred_final = pred_test.argmax(dim=1)\n",
        "\n",
        "# 4. ¡Generar el Reporte de Clasificación!\n",
        "# Comparamos las predicciones (pred_final) vs. las respuestas correctas (labels[test_mask])\n",
        "\n",
        "# Mover los tensores de la GPU/CPU a NumPy para que sklearn los entienda\n",
        "y_true = labels[test_mask].cpu().numpy()\n",
        "y_pred = pred_final.cpu().numpy()\n",
        "\n",
        "# ¡Imprimir el veredicto!\n",
        "print(classification_report(y_true, y_pred, target_names=['No Fraude (0)', 'Fraude (1)']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ23PxkzBesc",
        "outputId": "52e9c55f-27cf-49e0-87d8-a7876b34df3c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡Evaluando el modelo en los datos de Prueba!\n",
            "==========================================\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "No Fraude (0)       0.97      0.99      0.98       193\n",
            "   Fraude (1)       0.33      0.14      0.20         7\n",
            "\n",
            "     accuracy                           0.96       200\n",
            "    macro avg       0.65      0.57      0.59       200\n",
            " weighted avg       0.95      0.96      0.95       200\n",
            "\n"
          ]
        }
      ]
    }
  ]
}